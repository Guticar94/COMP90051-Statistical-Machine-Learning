{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.81\n",
      "1    0.19\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df1 = pd.read_json('../Data/domain1_train_data.json', lines=True)\n",
    "df2 = pd.read_json('../Data/domain2_train_data.json', lines=True)\n",
    "\n",
    "# Define Domains\n",
    "df1['domain'], df2['domain'] = 1, 2\n",
    "\n",
    "# Split set 1\n",
    "x1_tr, x_dv = train_test_split(df1, stratify=df1['label'], random_state=0, test_size=0.2)\n",
    "# Split set 2\n",
    "x2_1 = df2[df2['label'] == 1].sample(500, random_state=0)\n",
    "x2_0 = df2[df2['label'] == 0].sample(500, random_state=0)\n",
    "x2_tr = df2[[i not in list(pd.concat([x2_1, x2_0]).reset_index()['index']) for i in df2.index]].reset_index(drop=True)\n",
    "x2_dev = pd.concat([x2_1,x2_0]).reset_index(drop=True)\n",
    "\n",
    "# Train test sets\n",
    "x_train = pd.concat([x1_tr, x2_tr]).sample(frac=1).reset_index(drop=True)\n",
    "x_dev_ = pd.concat([x_dv, x2_dev]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Transform numbers to strings to treat them as tokens\n",
    "txt1 = [re.sub(',', '',', '.join([str(x) for x in tok])) for tok in x1_tr['text']]\n",
    "txt2 = [re.sub(',', '',', '.join([str(x) for x in tok])) for tok in x2_tr['text']]\n",
    "aug_txt = [re.sub(',', '', ', '.join([str(x) for x in tok])) for tok in x_train['text']]\n",
    "\n",
    "# Final train test sets\n",
    "x_tr_aug, y_train = aug_txt, x_train['label']\n",
    "x_dev_, y_dev = [re.sub(',', '',', '.join([str(x) for x in tok])) for tok in x_dev_['text']], np.array(x_dev_['label'].astype('float32'))\n",
    "\n",
    "# Print classes proportion\n",
    "print(round(y_train.value_counts()/len(y_train),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Tokens encoding to sparce matrix (Countv)\n",
    "Cvec = CountVectorizer(ngram_range=(8,9))\n",
    "x_train_c = Cvec.fit_transform(x_tr_aug)\n",
    "x_dev_c = Cvec.transform(x_dev_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 5154787)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_c.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Train models\n",
    "cl_aug_c = RidgeClassifier(alpha=1.0, solver=\"sparse_cg\").fit(x_train_c, y_train)\n",
    "cl_aug_c_w = RidgeClassifier(class_weight = \"balanced\", alpha=1.0, solver=\"sparse_cg\").fit(x_train_c, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model -DA using  Cvec:\t\ttr_acc: 1.000\tval_acc: 0.928\ttr_F1\" 1.000\tts_F1\" 0.929\n",
      "Model -DA using  Cvec-w:\ttr_acc: 1.000\tval_acc: 0.897\ttr_F1\" 1.000\tts_F1\" 0.901\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation scores\n",
    "sc_aug_c_tr, sc_aug_c_ts = cl_aug_c.score(x_train_c, y_train), cl_aug_c.score(x_dev_c, y_dev)\n",
    "sc_aug_c_w_tr, sc_aug_c_w_ts = cl_aug_c_w.score(x_train_c, y_train), cl_aug_c_w.score(x_dev_c, y_dev)\n",
    "# F1 scores\n",
    "f1_aug_c_tr, f1_aug_c_ts = f1_score(y_train, cl_aug_c.predict(x_train_c)), f1_score(y_dev, cl_aug_c.predict(x_dev_c))\n",
    "f1_aug_c_w_tr, f1_aug_c_w_ts = f1_score(y_train, cl_aug_c_w.predict(x_train_c)), f1_score(y_dev, cl_aug_c_w.predict(x_dev_c))\n",
    "\n",
    "# Print scores\n",
    "print(f'Model -DA using  Cvec:\\t\\ttr_acc: {sc_aug_c_tr:.3f}\\tval_acc: {sc_aug_c_ts:.3f}\\ttr_F1\" {f1_aug_c_tr:.3f}\\tts_F1\" {f1_aug_c_ts:.3f}')\n",
    "print(f'Model -DA using  Cvec-w:\\ttr_acc: {sc_aug_c_w_tr:.3f}\\tval_acc: {sc_aug_c_w_ts:.3f}\\ttr_F1\" {f1_aug_c_w_tr:.3f}\\tts_F1\" {f1_aug_c_w_ts:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:\n",
      "Model -DA using  Cvec-w:      tr_acc: 1.000      val_acc: 0.928      tr_F1\" 1.000      ts_F1\" 0.929      ROC_AUC: 0.897\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model:\")\n",
    "print(f'Model -DA using  Cvec-w:\\\n",
    "      tr_acc: {sc_aug_c_tr:.3f}\\\n",
    "      val_acc: {sc_aug_c_ts:.3f}\\\n",
    "      tr_F1\" {f1_aug_c_tr:.3f}\\\n",
    "      ts_F1\" {f1_aug_c_ts:.3f}\\\n",
    "      ROC_AUC: {roc_auc_score(y_dev, cl_aug_c_w.predict(x_dev_c))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df1, df2]).sample(frac=1).reset_index(drop=True)\n",
    "txt_full = [re.sub(',', '',', '.join([str(x) for x in tok])) for tok in df_full['text']]\n",
    "# Full vect\n",
    "Cvec_f = CountVectorizer(ngram_range=(8,9))\n",
    "x_full = Cvec_f.fit_transform(txt_full)\n",
    "y_full = df_full['label']\n",
    "# Full model\n",
    "cl_aug_c_w = RidgeClassifier(alpha=1.0, solver=\"sparse_cg\").fit(x_full, y_full)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json('../Data/test_data.json', lines=True)['text']\n",
    "test = [re.sub(',', '',', '.join([str(x) for x in tok])) for tok in test]\n",
    "test_c = Cvec_f.transform(test)\n",
    "\n",
    "preds = cl_aug_c_w.predict(test_c)\n",
    "\n",
    "test_df = pd.DataFrame(columns = ['id', 'value'])\n",
    "for idx, v in enumerate(preds):\n",
    "    test_df.loc[idx] = [idx, preds[idx]]\n",
    "test_df.to_csv('../Data/predictions_ridge.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
